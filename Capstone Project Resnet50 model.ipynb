{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Before we Begin downloading our module, let us create a more Keras friendly environment "}, {"metadata": {}, "cell_type": "code", "source": "conda create --name keras_env", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /home/wsuser/.conda/envs/keras_env\n\n\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate keras_env\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "conda activate keras_env", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "\nCommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n\n    $ conda init <SHELL_NAME>\n\nCurrently supported shells are:\n  - bash\n  - fish\n  - tcsh\n  - xonsh\n  - zsh\n  - powershell\n\nSee 'conda init --help' for more information and options.\n\nIMPORTANT: You may need to close and restart your shell after running 'conda init'.\n\n\n\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "conda install -c anaconda keras", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\n\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Let us import the required libraries"}, {"metadata": {}, "cell_type": "code", "source": "from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Now that we have created our Keras environment, let us download the data"}, {"metadata": {}, "cell_type": "code", "source": "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "--2021-07-05 09:06:26--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 261483817 (249M) [application/zip]\nSaving to: \u2018concrete_data_week4.zip.6\u2019\n\nconcrete_data_week4 100%[===================>] 249.37M  36.2MB/s    in 7.0s    \n\n2021-07-05 09:06:33 (35.4 MB/s) - \u2018concrete_data_week4.zip.6\u2019 saved [261483817/261483817]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!unzip -q concrete_data_week4.zip", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "[concrete_data_week4.zip]\r\n  End-of-central-directory signature not found.  Either this file is not\r\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\r\n  latter case the central directory and zipfile comment will be found on\r\n  the last disk(s) of this archive.\r\nunzip:  cannot find zipfile directory in one of concrete_data_week4.zip or\r\n        concrete_data_week4.zip.zip, and cannot find concrete_data_week4.zip.ZIP, period.\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Define Global Constants"}, {"metadata": {}, "cell_type": "markdown", "source": "Here, we will define constants that we will be using throughout the rest of the lab. \n\n1.  We are obviously dealing with two classes, so _num_classes_ is 2. \n2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n3.  We will training and validating the model using batches of 100 images.\n"}, {"metadata": {}, "cell_type": "code", "source": "num_classes = 2\n\nimage_resize = 224\n\nbatch_size_training = 100\nbatch_size_validation = 100", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n)\n\ntrain_generator = data_generator.flow_from_directory(\n    'concrete_data_week4/train',\n    target_size=(image_resize, image_resize),\n    batch_size=batch_size_training,\n    class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n    'concrete_data_week4/valid',\n    target_size=(image_resize, image_resize),\n    batch_size=batch_size_validation,\n    class_mode='categorical')", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Found 30001 images belonging to 2 classes.\nFound 9501 images belonging to 2 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Build, Compile and Fit Model"}, {"metadata": {}, "cell_type": "code", "source": "model = Sequential()", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(ResNet50(\n    include_top=False,\n    pooling='avg',\n    weights='imagenet',\n    ))", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 3s 0us/step\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.add(Dense(num_classes, activation='softmax'))", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.layers", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "[<tensorflow.python.keras.engine.training.Model at 0x7fd5b8216f10>,\n <tensorflow.python.keras.layers.core.Dense at 0x7fd59805ac10>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model.layers[0].layers", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fd5fbc9ff50>,\n <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fd5fa9cc590>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd663385810>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5fa9cc7d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5fbcabf10>,\n <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fd5fbcb13d0>,\n <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fd5fbcb5810>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f883b050>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f885bcd0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f87e1550>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f87e6510>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8810910>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f88164d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f8822850>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f88197d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8822650>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5fbc8b210>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f87c7d50>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f87ccb10>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f87ccbd0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f877d710>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f8785590>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f8785f50>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f872c7d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f87364d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f87389d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd60a0f62d0>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f86e9550>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f86ee510>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f86ee590>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f871a990>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f871fd10>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f86a2790>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f86d2b90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f8660190>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5fa9cc6d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8689610>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f8689650>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f868ed10>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f864d090>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f85ed550>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f85f2590>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f85f7550>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f85a3990>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f85b2090>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f868ee50>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f85ab310>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f863f910>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f85dbf90>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f85db050>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f8561c90>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f8561d10>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8590810>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f8597250>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f8596890>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8541d90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f854a5d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f854dad0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f84f9fd0>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f84fd710>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5fbcb5a90>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f8502790>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f84afb50>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f84b5490>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f84ba9d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8466950>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f846b590>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f846d550>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f849b990>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f83e1590>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f83e9050>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f83e6350>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8412c90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f8417050>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f841c6d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f83c7810>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f83ce210>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd60760af50>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f8337d50>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5f833ef90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f8340a50>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f82f8190>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f82a35d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5f82ac2d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f82b04d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f82db6d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d83bb210>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5f8340b10>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d83bbe90>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5f82f4650>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d83e3bd0>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5d83eb490>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d83f09d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d83f0a50>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d83a18d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d83a10d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d83ac950>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8351a90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d8357950>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d835c890>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8307cd0>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5d830c4d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d8312490>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d8312510>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d82bf950>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d82c3890>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d82c77d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d82f4b90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d8283190>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d827e550>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d82a5750>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5d82b0150>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d82b0f10>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d82b5150>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8262a90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d82700d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d826d490>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8219650>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d821bfd0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d821bdd0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d81c6b50>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5d81cee50>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d81d38d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d81d3990>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8186e50>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d817fe90>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d818ac90>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d81b3a10>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d8153910>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d813ca50>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d816ac10>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5d8170410>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d81743d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d8174450>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8121f90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d8126910>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d812b750>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d80d6b50>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d80e5150>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d80e2510>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d808d710>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5d8092590>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5d80b6f10>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d8047250>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8072fd0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b87ba710>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b87bf6d0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b87ebb10>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b87f7150>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5d8097150>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b87f5510>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5d8043a50>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b87a2710>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5b87a90d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b873cfd0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b87a5750>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b87599d0>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b875e1d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b8767110>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b8710910>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b8710150>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b871abd0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b86bdb10>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5b86c6d90>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b86c9210>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b86c9990>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b867ce50>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b867c050>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b8682cd0>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b86aca10>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b86ad910>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fd5b86b7850>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fd5b8263c90>,\n <tensorflow.python.keras.layers.merge.Add at 0x7fd5b8267490>,\n <tensorflow.python.keras.layers.core.Activation at 0x7fd5b826b450>,\n <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fd5b826b4d0>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model.layers[0].trainable = False", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "steps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(validation_generator)\nnum_epochs = 2", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "fit_history = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch_training,\n    epochs=num_epochs,\n    validation_data=validation_generator,\n    validation_steps=steps_per_epoch_validation,\n    verbose=1,\n)", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Epoch 1/2\n301/301 [==============================] - 6789s 23s/step - loss: 0.0336 - accuracy: 0.9873 - val_loss: 0.0066 - val_accuracy: 0.9986\nEpoch 2/2\n301/301 [==============================] - 6739s 22s/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9989\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.save('classifier_resnet_model.h5')", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}